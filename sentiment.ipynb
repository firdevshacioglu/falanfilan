{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cf0086f-9731-4b1b-9ef7-021d0306a4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Firdevs\n",
      "[nltk_data]     Sonay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Firdevs\n",
      "[nltk_data]     Sonay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Firdevs\n",
      "[nltk_data]     Sonay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Firdevs\n",
      "[nltk_data]     Sonay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import nltk as nlp\n",
    "nltk.download('stopwords')\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('turkish'))\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e1ea39b-f015-4aaf-9ac8-161f98bd54cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>biri bana bu filmde benim anlamadigim bisey ol...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ya çocuklar ilk filmin sonunda büyüdüler ya bu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>film biraz daha uzun sürse harbi kiyameti göre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>pek orjinal bi cinayet yok ama orjinal oyuncul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>film tek kelimeyle muhtesemdi heleki sonundaki...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            comment  Label\n",
       "0           0  biri bana bu filmde benim anlamadigim bisey ol...      0\n",
       "1           1  ya çocuklar ilk filmin sonunda büyüdüler ya bu...      1\n",
       "2           2  film biraz daha uzun sürse harbi kiyameti göre...      0\n",
       "3           3  pek orjinal bi cinayet yok ama orjinal oyuncul...      0\n",
       "4           4  film tek kelimeyle muhtesemdi heleki sonundaki...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('C:\\\\Users\\\\Firdevs Sonay\\\\Desktop\\\\data\\\\train.csv', encoding='unicode_escape')\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "010322b7-451e-4994-ba57-2b6109c7923d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>biri bana bu filmde benim anlamadigim bisey ol...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ya çocuklar ilk filmin sonunda büyüdüler ya bu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>film biraz daha uzun sürse harbi kiyameti göre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>pek orjinal bi cinayet yok ama orjinal oyuncul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>film tek kelimeyle muhtesemdi heleki sonundaki...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            comment  Label\n",
       "0           0  biri bana bu filmde benim anlamadigim bisey ol...      0\n",
       "1           1  ya çocuklar ilk filmin sonunda büyüdüler ya bu...      1\n",
       "2           2  film biraz daha uzun sürse harbi kiyameti göre...      0\n",
       "3           3  pek orjinal bi cinayet yok ama orjinal oyuncul...      0\n",
       "4           4  film tek kelimeyle muhtesemdi heleki sonundaki...      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('C:\\\\Users\\\\Firdevs Sonay\\\\Desktop\\\\data\\\\train.csv', encoding= 'unicode_escape')\n",
    "df_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ce26ba0-5d3c-4284-a65d-189b48456a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"[^abcçdefgğhıijklmnoöprsştuüvyz]\",\" \",text)\n",
    "    text=nltk.word_tokenize(text)\n",
    "    text =[word for word in text if not word in set(stopwords.words(\"turkish\"))]\n",
    "    lemma=nlp.WordNetLemmatizer()\n",
    "    text=[lemma.lemmatize(word) for word in text]\n",
    "    text=\" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb16461-d3d7-43b0-84f2-0534b279244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"clean_text\"]=df_train[\"comment\"].apply(lambda x: pre_processing(x))\n",
    "df_test[\"clean_text\"]=df_test[\"comment\"].apply(lambda x: pre_processing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb23eb6-3d99-4e36-8715-e547fcde9e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd65483-27b9-403b-825e-ab928c8fa21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_train[\"clean_text\"]\n",
    "X_test=df_test[\"clean_text\"]\n",
    "y_train=df_train[\"Label\"]\n",
    "y_test=df_test[\"Label\"]\n",
    "\n",
    "print(\"x_train\",X_train.shape)\n",
    "print(\"x_test\",X_test.shape)\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb1d6aa-28dc-452a-9771-caa38260c14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "LogisticRegression = Pipeline([('tfidf', TfidfVectorizer()),('clf', LogisticRegression())])\n",
    "\n",
    "LogisticRegression .fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7776b1b2-b8c3-4c38-bc22-0dcbb9bfe8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_confusion_matrix(Y_test, Y_preds):\n",
    "    conf_mat = confusion_matrix(Y_test, Y_preds)\n",
    "    #print(conf_mat)\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    plt.matshow(conf_mat, cmap=plt.cm.Blues, fignum=1)\n",
    "    plt.yticks(range(2), range(2))\n",
    "    plt.xticks(range(2), range(2))\n",
    "    plt.colorbar();\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(i-0.2,j+0.1, str(conf_mat[j, i]), color='tab:red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dfafca-8484-4eaa-b183-7824f3f9322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report,precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cv_scores = cross_val_score(LogisticRegression, X_train, y_train, cv=10)\n",
    "print(\"CV average score: %.2f\" % cv_scores.mean())\n",
    "\n",
    "result = LogisticRegression.predict(X_test)\n",
    "cr = classification_report(y_test, result)\n",
    "print(cr)\n",
    "\n",
    "\n",
    "print('Train Accuracy : %.3f'%LogisticRegression.score(X_train, y_train))\n",
    "print('Test Accuracy : %.3f'%LogisticRegression.score(X_test, y_test))\n",
    "\n",
    "\n",
    "\n",
    "y_pred = LogisticRegression.predict(X_test)\n",
    "print(precision_score(y_test, y_pred ,average='macro') , \": is the precision score\")\n",
    "print(recall_score(y_test, y_pred,average='macro'), \": is the recall score\")\n",
    "print(f1_score(y_test, y_pred ,average='macro'), \": is the f1 score\")\n",
    "\n",
    "plot_confusion_matrix(y_test, LogisticRegression.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c653b1c4-f8ee-49cb-8865-7653e2aca8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install requests\n",
    "!pip install html5lib\n",
    "!pip install bs4\n",
    "!pip install selenium\n",
    "!pip install pandas tabulate prettytable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f738af3-ba23-4953-95f6-383268afd01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = \"https://hdfilmcehennemi.cx/titanik-izle/\"\n",
    "r = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "# Yorumların bulunduğu div etiketlerini bulma\n",
    "comment_divs = soup.find_all(\"div\", {\"class\": \"comment-body\"})\n",
    "\n",
    "# Yorum metinlerini çekme\n",
    "comment_list = []\n",
    "for comment_div in comment_divs:\n",
    "    p_tag = comment_div.find(\"p\")\n",
    "    if p_tag:\n",
    "        comment_list.append(p_tag.text.strip())\n",
    "\n",
    "# Yorumları yazdırma\n",
    "if comment_list:\n",
    "    for idx, comment in enumerate(comment_list):\n",
    "        print(f\"Comment {idx+1}: {comment}\")\n",
    "else:\n",
    "    print(\"No comments found\")\n",
    "\n",
    "# Belirli bir yorumu yazdırma\n",
    "try:\n",
    "    print(comment_list[3])\n",
    "except IndexError:\n",
    "    print(\"There are less than 4 comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b32cf91-3f3e-4a8e-9462-bc94e199998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_comments(comments, pipeline):\n",
    "    positive_comments = []\n",
    "    negative_comments = []\n",
    "\n",
    "    for comment in comments:\n",
    "        prediction = pipeline.predict([comment])\n",
    "        proportion = pipeline.predict_proba([comment])\n",
    "\n",
    "        if prediction[0] == 1:\n",
    "            positive_comments.append((comment, proportion[0][1]))\n",
    "        else:\n",
    "            negative_comments.append((comment, proportion[0][0]))\n",
    "\n",
    "    return positive_comments, negative_comments\n",
    "\n",
    "positive_comments, negative_comments = analyze_comments(comment_list, LogisticRegression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d529f8c-5d9b-49bf-81f5-30d339acb777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "table = PrettyTable()\n",
    "\n",
    "table.field_names = [\"Comment\", \"Sentiment Probability\", \"Sentiment\"]\n",
    "\n",
    "for comment, sentiment_prob in positive_comments:\n",
    "    if len(comment) > 50:\n",
    "        comment = comment[:50] + \"...\"\n",
    "    table.add_row([comment, f\"{sentiment_prob:.2f}\", \"Positive\"])\n",
    "\n",
    "for comment, sentiment_prob in negative_comments:\n",
    "    if len(comment) > 50:\n",
    "        comment = comment[:50] + \"...\"\n",
    "    table.add_row([comment, f\"{sentiment_prob:.2f}\", \"Negative\"])\n",
    "\n",
    "\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b68af2-0c19-4545-b2d6-bf6b4b904357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_comments(comments, pipeline):\n",
    "    positive_comments = []\n",
    "    negative_comments = []\n",
    "\n",
    "    for comment in comments:\n",
    "        prediction = pipeline.predict([comment])\n",
    "        proportion = pipeline.predict_proba([comment])\n",
    "\n",
    "        if prediction[0] == 1:\n",
    "            positive_comments.append((comment, proportion[0][1]))\n",
    "        else:\n",
    "            negative_comments.append((comment, proportion[0][0]))\n",
    "\n",
    "    return positive_comments, negative_comments\n",
    "\n",
    "positive_comments, negative_comments = analyze_comments(comment_list, LogisticRegression)\n",
    "\n",
    "num_positive = len(positive_comments)\n",
    "num_negative = len(negative_comments)\n",
    "\n",
    "data = {'Sentiment': ['Positive', 'Negative'],\n",
    "        'Count': [num_positive, num_negative]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Yorum Sentimentlerinin Sayısı:\")\n",
    "print(df)\n",
    "\n",
    "# Dağılımı gösteren çubuk grafiği ve pasta grafiği\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Çubuk grafiği\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(df['Sentiment'], df['Count'], color=['purple', 'gray'])\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Sentiment Distribution of Comments (Bar)')\n",
    "\n",
    "# Pasta grafiği\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(df['Count'], labels=df['Sentiment'], autopct='%1.1f%%', colors=['blue', 'orange'])\n",
    "plt.title('Sentiment Distribution of Comments (Pie)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86678e0f-2477-4f73-a423-d2426dd904a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_list = [\"comment1\", \"comment2\", \"comment3\", \"comment4\", \"comment5\"]\n",
    "\n",
    "predictions = [0, 1, 1, 0, 1]\n",
    "\n",
    "y_test = [0, 1, 0, 0, 1]\n",
    "\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = len(comment_list)\n",
    "\n",
    "for i in range(total_predictions):\n",
    "\n",
    "    if predictions[i] == y_test[i]:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = (correct_predictions / total_predictions) * 100\n",
    "print(\"Başarı Yüzdesi: {:.2f}%\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb546e2-4e1a-46a6-a303-1dee62b0514f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
